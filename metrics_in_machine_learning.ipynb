{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942e0ae1",
   "metadata": {},
   "source": [
    "# Метрики качества в задачах машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b529e",
   "metadata": {},
   "source": [
    "## 1. Метрики качества в задачах регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0a032",
   "metadata": {},
   "source": [
    "#### Применение метрик качества в машинном обучении\n",
    "\n",
    "Метрики качества могут использоваться:\n",
    "> Для задания функционала ошибки (используется при обучении);\n",
    "\n",
    "> Для подбора гиперпараметров (используется при измерении качества на кросс-валидации). В том числе можно использовать другую метрику, которая отличается от метрики, с помощью которой построен функционал ошибки;\n",
    "\n",
    "> Для оценивания итоговой модели: пригодна ли модель для решения задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712fbf3",
   "metadata": {},
   "source": [
    "### 1.1. Среднеквадратичная ошибка (Mean Squared Error, MSE)\n",
    "\n",
    "$$MSE(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} ( a(x_i) - y_i )^2$$\n",
    "\n",
    "Такой функционал легко оптимизировать, используя, например, метод градиентного спуска.\n",
    "\n",
    "Этот функционал сильно штрафует за большие ошибки, так как отклонения возводятся в квадрат. Это приводит к тому, что штраф на выбросе будет очень сильным, и алгоритм будет настраиваться на выбросы. Другими словами, алгоритм будет настраиваться на такие объекты, на которые не имеет смысл настраиваться.\n",
    "\n",
    "Отметим, что величина среднеквадратичного отклонения **плохо интерпретируется**, поскольку не сохраняет единицы измерения — так, если мы предсказываем цену в рублях, то $MSE$ будет измеряться в квадратах рублей. Чтобы избежать проблем с интерпретируемостью, используют **корень из среднеквадратичной ошибки**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3390ad6",
   "metadata": {},
   "source": [
    "### 1.2. Корень среднеквадратичной ошибки (Root Mean Squared Error, RMSE)\n",
    "\n",
    "$$RMSE(a, X) = \\sqrt{\\frac{1}{l} \\sum_{i = 1}^{l} ( a(x_i) - y_i )^2}$$\n",
    "\n",
    "Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения, но не позволяет сделать выводы о том, насколько хорошо данная модель решает задачу.\n",
    "\n",
    "Например, $MSE = 10$ является очень плохим показателем, если целевая переменная принимает значения от 0 до 1, и очень хорошим, если целевая переменная лежит в интервале (10000, 100000). В таких ситуациях вместо среднеквадратичной ошибки полезно использовать **коэффициент детерминации**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e0658",
   "metadata": {},
   "source": [
    "### 1.3. Коэффициент детерминации (Coefficient of Determination, $R^2$)\n",
    "\n",
    "Коэффициент детерминации $R^2(a, X)$:\n",
    "\n",
    "$$R^2(a, X) = 1 - \\frac{\\sum_{i = 1}^{l} ( a(x_i) - y_i )^2}{\\sum_{i = 1}^{l} ( y_i - \\bar{y} )}, \\ \\ \\ \\bar{y} = \\frac{1}{l} \\sum_{i = 1}^{l} y_i,$$\n",
    "\n",
    "позволяет интерпретировать значение среднеквадратичной ошибки.\n",
    "\n",
    "Коэффициент детерминации измеряет долю дисперсии, объяснённую моделью, в общей дисперсии целевой переменной.\n",
    "\n",
    "Этот коэффициент показывает, какую долю дисперсии (разнообразия ответов) во всем целевом векторе $y$ модель смогла объяснить.\n",
    "\n",
    "Для разумных моделей коэффициент детерминации лежит в следующих пределах: $0 \\leq R^2 \\leq 1,$ причем \n",
    "\n",
    "> $R^2 = 1$ соответствует случаю *идеальной модели*;\n",
    "\n",
    "> $R^2 = 0$ — модель на уровне оптимальной *«константной»*;\n",
    "\n",
    "> $R^2 < 0$ — модель хуже «константной».\n",
    "\n",
    "**Оптимальным константым алгоритмом** называется такой алгоритм, который возвращает всегда среднее значение ответов $\\bar{y}$ для объектов обучающей выборки.\n",
    "\n",
    "Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a62b81",
   "metadata": {},
   "source": [
    "### 1.4. Средняя абсолютная ошибка (Mean Absolute Error)\n",
    "\n",
    "Похожий на предыдущий функционал качества — средняя абсолютная ошибка:\n",
    "\n",
    "$$MAE(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} | a(x_i) - y_i | $$\n",
    "\n",
    "Этот функционал сложнее минимизировать, так как у модуля производная не существует в нуле. Но у такого функционала больше устойчивость к выбросам, так как штраф за сильное отклонение гораздо меньше.\n",
    "\n",
    "Модуль отклонения не является дифференцируемым, но при этом менее чувствителен к выбросам. Квадрат отклонения, по сути, делает особый акцент на объектах с сильной ошибкой, и метод обучения будет в первую очередь стараться уменьшить отклонения на таких объектах. Если же эти объекты являются выбросами (то есть значение целевой переменной на них либо ошибочно, либо относится к другому распределению и должно быть проигнорировано), то такая расстановка акцентов приведёт к плохому качеству модели. Модуль отклонения в этом смысле гораздо более терпим к сильным ошибкам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb9ed4",
   "metadata": {},
   "source": [
    "### 1.5. Cреднеквадратичная логарифмическая ошибка (Mean Squared Logarithmic Error, MSLE)\n",
    "\n",
    "$$MSLE(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} \\big( \\log (a(x_i) + 1) - \\log (y_i + 1) \\big) ^ 2 $$\n",
    "\n",
    "Данная метрика подходит для задач с неотрицательной целевой переменной. За счёт логарифмирования ответов и прогнозов мы скорее **штрафуем за отклонения в порядке величин, чем за отклонения в их значениях**. Также следует помнить, что логарифм не является симметричной функцией, и поэтому данная функция потерь штрафует заниженные прогнозы сильнее, чем завышенные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bf977",
   "metadata": {},
   "source": [
    "### 1.6. Cредняя абсолютная процентная ошибка (Mean Absolute Percentage Error, MAPE)\n",
    "\n",
    "$$MAPE(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} \\big| \\frac{y_i - a_i}{y_i} \\big|$$\n",
    "\n",
    "Данный функционал часто используется в задачах прогнозирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6f72f",
   "metadata": {},
   "source": [
    "### 1.7. Cимметричный MAPE (Symmetric Mean Absolute Percentage Error, SMAPE)\n",
    "\n",
    "$$SMAPE(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} \\big| \\frac{y_i - a_i}{(|y_i| + |a_i|) / 2} \\big|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee710af",
   "metadata": {},
   "source": [
    "### 1.8. Квантильная ошибка\n",
    "\n",
    "#### Несимметричные потери\n",
    "\n",
    "До этого рассматривались симметричные модели, то есть такие, которые штрафуют как за недопрогноз, так и за перепрогноз. Но существуют такие задачи, в которых эти ошибки имеют разную цену.\n",
    "\n",
    "Пусть, например, требуется оценить спрос на ноутбуки. В этом случае заниженный прогноз приведет к потере лояльности покупателей и потенциальной прибыли (будет закуплено недостаточное количество ноутбуков), а завышенный — только к не очень большим дополнительным расходам на хранение непроданных ноутбуков. Чтобы учесть это, функция потерь должна быть несимметричной и сильнее штрафовать за недопрогноз, чем за перепрогноз.\n",
    "\n",
    "В таких случаях хорошо подходит квантильная ошибка или квантильная функция потерь\n",
    "\n",
    "$$\\rho_{\\tau} (a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} \\big( (\\tau - 1) [y_i < a(x_i)] + \\tau [y_i \\geq a(x_i)] \\big) \\ (y_i - a(x_i)).$$\n",
    "\n",
    "\n",
    "Параметр $\\tau \\in [0, 1]$ определяет то, за что нужно штрафовать сильнее — за недопрогноз или перепрогноз.\n",
    "\n",
    "Если $\\tau$ ближе к 1, штраф будет больше за недопрогноз, а если, наоборот, ближе к 0 — за перепрогноз.\n",
    "\n",
    "\n",
    "#### Вероятностный смысл квантильной ошибки\n",
    "\n",
    "Чтобы разобраться, почему такая функция потерь называется квантильной, нужно разобраться с ее вероятностным смыслом. Пусть один и тот же объект $x$ с одним и тем же признаковым описанием повторяется в выборке $n$ раз, но на каждом из повторов — свой ответ $y_1, ..., y_n$.\n",
    "\n",
    "Такое может возникнуть при измерении роста человека. Измерения роста одного и того же человека могут отличаться ввиду ошибки прибора, а также зависеть от самого человека (может сгорбиться или выпрямиться).\n",
    "\n",
    "При этом алгоритм должен для одного и того же признакового описания возвращать одинаковый прогноз. Другими словами, необходимо решить, какой прогноз оптимален для $x$ с точки зрения различных функционалов ошибки.\n",
    "\n",
    "Оказывается, что\n",
    "> если используется квадратичный функционал ошибки, то наиболее оптимальным прогнозом будет средний ответ на объектах;\n",
    "\n",
    "> если абсолютный, то медиана ответов.\n",
    "\n",
    "> если же будет использоваться квантильная функция потерь, наиболее оптимальным прогнозом, будет $\\tau$ - квантиль.\n",
    "\n",
    "В этом и состоит вероятностный смысл квантильной ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a19cc",
   "metadata": {},
   "source": [
    "## 2. Метрики качества в задачах классификации\n",
    "\n",
    "В этом блоке речь пойдет о том, как измерять качество в задачах классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70617e0a",
   "metadata": {},
   "source": [
    "### 2.1. Доля правильных ответов\n",
    "\n",
    "Как меру качества в задачах классификации естественно использовать долю неправильных ответов:\n",
    "\n",
    "$$\\frac{1}{l} \\sum_{i = 1}^{l} [ a(x_i) \\neq y_i ]$$\n",
    "\n",
    "Однако в задачах классификации принято выбирать метрики таким образом, чтобы их нужно было максимизировать, тогда как в задачах регрессии — так, чтобы их нужно было минимизировать. Поэтому определяют:\n",
    "\n",
    "$$accuracy(a, X) = \\frac{1}{l} \\sum_{i = 1}^{l} [ a(x_i) = y_i ]$$\n",
    "\n",
    "Эта метрика качества проста и широко используется, однако имеет несколько существенных недостатков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca2bb4",
   "metadata": {},
   "source": [
    "#### Недостаток 1: Несбалансированные выборки\n",
    "\n",
    "Первая проблема связана с несбалансированными выборками.\n",
    "\n",
    "**Пример**. Пусть в выборке 1000 объектов, из которых 950 относятся к классу −1 и 50 — к классу +1. Рассматривается бесполезный (поскольку не восстанавливает никаких закономерностей в данных) константный классификатор, который на всех объектах возвращает ответ −1. Но доля правильных ответов на этих данных будет равна 0.95, что несколько много для бесполезного классификатора.\n",
    "\n",
    "Чтобы «бороться» с этой проблемой, используется следующий факт. Пусть $q_0$ - доля объектов самого крупного класса, тогда доля правильных ответов для разумных алгоритмов $accuracy \\in [q_0, 1]$, а не $[0.5, 1]$, как это можно было бы ожидать. Поэтому, если получается высокий процент правильных ответов, это может быть связано не с тем, что построен хороший классификатор, а с тем, что какого-то класса сильно больше, чем остальных.\n",
    "\n",
    "#### Недостаток 2: Цены ошибок\n",
    "\n",
    "Долей верных ответов никак не учитывает разные цены разных типов ошибок. Тогда как цены действительно могут быть разными.\n",
    "\n",
    "**Пример**. В задаче кредитного скоринга, то есть в задаче принятия решения относительно выдачи кредита, сравниваются две модели. При использовании первой модели кредит будет выдан 100 клиентам, 80 из которых его вернут. Во второй модели, более консервативной, кредит был выдан только 50 клиентам, причем вернули его в 48 случаях. То, какая из двух моделей лучше, зависит от того, цена какой из ошибок выше: не дать кредит клиенту, который мог бы его вернуть, или выдать кредит клиенту, который его не вернет. Таким образом, нужны дополнительные метрики качества, которые учитывают цены той или иной ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32678b",
   "metadata": {},
   "source": [
    "### 2.2. Точность и полнота\n",
    "\n",
    "В этом разделе пойдет речь о метриках качества классификации, которые позволяют учитывать разные цены ошибок. В конце предыдущего разделе уже было сказано, что цены ошибок действительно могут быть разными. Так, в задаче банковского скоринга необходимо принять решение, что хуже: выдать кредит «плохому» клиенту или не выдать кредит «хорошему» клиенту. Доля верных ответов не способна учитывать цены разных ошибок и поэтому не может дать ответа на этот вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca56d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
